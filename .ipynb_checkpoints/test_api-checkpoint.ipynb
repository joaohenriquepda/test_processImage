{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Faces and things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - *- coding: utf- 8 - *-\n",
    "# import the necessary packages\n",
    "import cv2\n",
    "import sys\n",
    "import requests\n",
    "import cv2\n",
    "import urllib\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the URL to our face detection API\n",
    "faceCascade = cv2.CascadeClassifier(\"/home/joaohenrique/opencv/data/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier('/home/joaohenrique/opencv/data/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "url = \"http://localhost:8000/face_detection/detect/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use our face detection API to find faces in images via image URL\n",
    "#image = urllib.urlopen(\"\")\n",
    "\n",
    "#image = urllib.urlopen(\"https://scontent-gru2-1.xx.fbcdn.net/v/t1.0-9/1071_428356690554276_2078489730_n.jpg?oh=085d79a7dba9969471b0e158bd63af91&oe=58F729BF\")\n",
    "#image1 = urllib.urlopen(\"https://scontent-gru2-1.xx.fbcdn.net/v/t1.0-9/10154374_887236344701678_2835358613574848918_n.jpg?oh=1dc31d79b8eb6e1a37b7d1461e94552e&oe=58B2E94D\")\n",
    "#image2 = urllib.urlretrieve(\"https://scontent-gru2-1.xx.fbcdn.net/v/t1.0-9/r270/12115481_972095072848255_4032544286627409172_n.jpg?oh=b9faa0642d0584e9e24180c06c5563fe&oe=58B192D7\", \"image2.jpg\")\n",
    "#image3 = urllib.urlopen(\"https://scontent-gru2-1.xx.fbcdn.net/v/t1.0-9/12299367_748838145220475_529083328194189411_n.jpg?oh=a68f94b6c023d52bd1f56835ce13256d&oe=58B1C857\")\n",
    "\n",
    "# output = open(\"image.jpg\",\"wb\")\n",
    "# output.write(image.read())\n",
    "# output.close()\n",
    "#a\n",
    "# output = open(\"image1.jpg\",\"wb\")\n",
    "# output.write(image1.read())\n",
    "# output.close()\n",
    "#\n",
    "# output = open(\"image3.jpg\",\"wb\")\n",
    "# output.write(image3.read())\n",
    "# output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read the images\n",
    "\n",
    "image = cv2.imread(\"image.jpg\")\n",
    "payload = {\"image\": open(\"image.jpg\", \"rb\")}\n",
    "\n",
    "r = requests.post(url, files=payload).json()\n",
    "\n",
    "# loop over the faces and draw them on the image\n",
    "for (startX, startY, endX, endY) in r[\"faces\"]:\n",
    "    cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "#show the output image\n",
    "cv2.imshow(\"image.jpg\", image)\n",
    "\n",
    "\n",
    "lap = cv2.Laplacian(image, cv2.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv2.imshow(\" Laplacian\" , lap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "image1 = cv2.imread(\"image1.jpg\")\n",
    "payload = {\"image\": open(\"image1.jpg\", \"rb\")}\n",
    "r = requests.post(url, files=payload).json()\n",
    "\n",
    "print 'Total faces:' ,r[\"num_faces\"]\n",
    "print 'Total eyes:', r[\"num_eyes\"]\n",
    "\n",
    "print 'Vetor eyes:', r[\"eyes\"]\n",
    "\n",
    "# loop over the faces and draw them on the image\n",
    "for (x, y, w, h) in r[\"faces\"]:\n",
    "    cv2.rectangle(image1, (x, y), (w, h), (0, 255, 0), 2)\n",
    "    \n",
    "\n",
    "    for (ex,ey,ew,eh) in r[\"eyes\"]:\n",
    "        cv2.rectangle(image1,(ex,ey),(ew,eh),(0,255,0),2)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"image1.jpg\", image1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "image2 = cv2.imread(\"image2.jpg\")\n",
    "payload = {\"image\": open(\"image2.jpg\", \"rb\")}\n",
    "r = requests.post(url, files=payload).json()\n",
    "\n",
    "# loop over the faces and draw them on the image\n",
    "for (startX, startY, endX, endY) in r[\"faces\"]:\n",
    "    cv2.rectangle(image2, (startX, startY), (endX, endY), (0, 250, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"image2.jpg\", image2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "image3 = cv2.imread(\"image3.jpg\")\n",
    "payload = {\"image\": open(\"image3.jpg\", \"rb\")}\n",
    "r = requests.post(url, files=payload).json()\n",
    "\n",
    "\n",
    "\n",
    "# loop over the faces and draw them on the image\n",
    "for (startX, startY, endX, endY) in r[\"faces\"]:\n",
    "\tcv2.rectangle(image3, (startX, startY), (endX, endY), (0, 250, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"image3.jpg\",image3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When everything is done, release the capture\n",
    "#video_capture.release()\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I count 33 coins in this image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image = cv2.imread(\"coins.png\") \n",
    "image = cv2.imread(\"coins3.jpg\") \n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "cv2.imshow(\"Edges\", edged)\n",
    "\n",
    "im2, cnts, hierarchy = cv2.findContours(edged,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "\n",
    "print \"I count %d coins in this image\" % len(cnts)\n",
    "\n",
    "coins = image.copy()\n",
    "cv2.drawContours(coins, cnts, -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Coins\", coins)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "all_images = np.hstack((image, coins))\n",
    "cv2.imshow(\"Contours\", all_images)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Colocado como markdown para execução\n",
    "\n",
    "for (i, c) in enumerate(cnts):\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "\tprint \"Coin #%d\" % (i + 1)\n",
    "\tcoin = image[y:y + h, x: x + w]\n",
    "\tcv2.imshow(\"Coin\", coin)\n",
    "\n",
    "\tmask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "\t(center, radius) = cv2.minEnclosingCircle(c)\n",
    "\tcv2.circle(mask, tuple(map(int, center)), int(radius), 255, -1)\n",
    "\tmask = mask[y:y + h, x:x + w]\n",
    "\n",
    "\tcv2.imshow(\"Masked Coin\", cv2.bitwise_and(coin, coin, mask = mask))\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
